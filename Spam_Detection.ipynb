{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOof/gyQXBwqmrLyWISjnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sindhu2808/Spam-Detectionn/blob/main/Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI1JMpoCvNG-",
        "outputId": "833c24fb-27ed-441b-d2ad-f259389fe378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ds = pd.read_csv('spam.csv' , encoding='cp437')\n",
        "X = ds.iloc[:, :-1].values\n",
        "Y = ds.iloc[:, -1].values\n",
        "y=ds.iloc[:,0].values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_nnaiA9jwLZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "orpus=[]\n",
        "for i in range(0,5572):\n",
        "    review = re.sub('[^a-zA-Z]',' ',ds['v2'][i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    ps=PorterStemmer()\n",
        "    review=[ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review=' '.join(review)\n",
        "    orpus.append(review)\n"
      ],
      "metadata": {
        "id": "mRjL_Srqwfrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=3000)\n",
        "x=cv.fit_transform(orpus).toarray()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "metadata": {
        "id": "G7uMB6hhwjEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier=GaussianNB()\n",
        "classifier.fit(X_train,y_train)\n",
        "pred=classifier.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "print(\"Naive Bayes Classifier:-\")\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, pred)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, pred)))\n",
        "print('Recall score: {}'.format(recall_score(y_test, pred)))\n",
        "print('F1 score: {}\\n'.format(f1_score(y_test, pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D9OToahwLMI",
        "outputId": "671e94b1-603d-4594-f979-96b14f6e7c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier:-\n",
            "Accuracy score: 0.8618834080717489\n",
            "Precision score: 0.4528301886792453\n",
            "Recall score: 0.9302325581395349\n",
            "F1 score: 0.6091370558375634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier1=RandomForestClassifier(n_estimators=15,criterion='entropy')\n",
        "classifier1.fit(X_train,y_train)\n",
        "predRF=classifier1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "print(\"Random Forest Classifier:-\")\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predRF)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predRF)))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predRF)))\n",
        "print('F1 score: {}\\n'.format(f1_score(y_test, predRF)))\n",
        "\n"
      ],
      "metadata": {
        "id": "fI2khjvjwaRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e686d2a-0b3f-4ebb-967e-c6bd9fc3f3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier:-\n",
            "Accuracy score: 0.9766816143497757\n",
            "Precision score: 0.9724770642201835\n",
            "Recall score: 0.8217054263565892\n",
            "F1 score: 0.8907563025210085\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier2 = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "classifier2.fit(X_train, y_train)\n",
        "predLR= classifier2.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "print(\"Logistic Regression Classifier:-\")\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predLR)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predLR)))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predLR)))\n",
        "print('F1 score: {}\\n'.format(f1_score(y_test, predLR)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UriZ_MowUOA",
        "outputId": "6a9c8982-cbe2-452a-f894-390c7c56725d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier:-\n",
            "Accuracy score: 0.9856502242152466\n",
            "Precision score: 0.959349593495935\n",
            "Recall score: 0.9147286821705426\n",
            "F1 score: 0.9365079365079364\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree=DecisionTreeClassifier(max_depth=10,random_state=101,max_features=None,min_samples_leaf=15)\n",
        "dtree.fit(X_train,y_train)\n",
        "predDT=dtree.predict(X_test)\n",
        "dtree.score(X_test, y_test)\n",
        "predLR= classifier2.predict(X_test)\n",
        "print(\"Decision Tree Classifier:-\")\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predDT)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predDT)))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predDT)))\n",
        "print('F1 score: {}\\n'.format(f1_score(y_test, predDT)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w43q26F-wWmM",
        "outputId": "fd937c05-770d-4e71-b3be-010f6e30e532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier:-\n",
            "Accuracy score: 0.9605381165919282\n",
            "Precision score: 0.9473684210526315\n",
            "Recall score: 0.6976744186046512\n",
            "F1 score: 0.8035714285714286\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm=SVC(kernel=\"linear\",C=0.025,random_state=101)\n",
        "svm.fit(X_train,y_train)\n",
        "predSVM=svm.predict(X_test)\n",
        "svm.score(X_test,y_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Support Vector Machine Classifier:-\")\n",
        "print('Accuracy score: {}'.format(accuracy_score(y_test, predSVM)))\n",
        "print('Precision score: {}'.format(precision_score(y_test, predSVM)))\n",
        "print('Recall score: {}'.format(recall_score(y_test, predSVM)))\n",
        "print('F1 score: {}\\n'.format(f1_score(y_test, predSVM)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luhwGh3GwY2E",
        "outputId": "240d5ad2-0200-4dee-fbf5-1e887429e2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine Classifier:-\n",
            "Accuracy score: 0.9811659192825112\n",
            "Precision score: 1.0\n",
            "Recall score: 0.8372093023255814\n",
            "F1 score: 0.9113924050632911\n",
            "\n"
          ]
        }
      ]
    }
  ]
}